# ðŸŽ¯ Project Prompt for AI Co-Development

I'm building a voice-based AI web app to help non-native English speakers, especially(*not especially, like) learners from Bangladesh, improve their English speaking proficiency. The app has two main modes:

1. **IELTS Practice Mode** â€“ with structured Parts 1â€“3 speaking questions and feedback aligned to IELTS Band Descriptors (fluency, coherence, lexical resource, grammar, pronunciation).  
2. **Free Chat Mode** â€“ where the user speaks freely with the AI and receives periodic fluency tips and general feedback.

The app will use:
- **Voice input (mic)** â†’ Transcription via STT  
- **LLM (via API initially)** â†’ to handle conversation and generate feedback  
- **TTS** â†’ for speaking responses in Free Chat Mode  
- The UI and backend will be deployed in the cloud; currently considering Gradio for simplicity, but open to better frameworks.

ðŸ”§ Architecture should prioritize performance, (*prioritize free of cost) and remain lightweight enough for free or low-tier cloud environments.

ðŸ‘¥ Please consider common speech patterns of Bangladeshi English learners when designing feedback logic.(* exclude this)

ðŸ’¡ I want help with:
- Suggesting a modular architecture for both modes (IELTS and Free Chat)  
- Selecting lightweight, accurate STT and TTS tools (e.g., Whisper, Google STT, Nari, Coqui)  
- Building the system step-by-step using clean, testable Python modules  
- Writing feedback evaluation prompts and logic based on IELTS band descriptors  
- Designing general feedback strategies for Free Chat Mode  
- Keeping the system optimized for cloud deployment  

ðŸš¨ I want to approach this as a research-grade project â€” the final goal is a fully working web app and a publishable paper. Please guide me like a co-developer and research assistant.

(* I want to build prototype by 30 days, today is -(*date), start user test by 15th July, Present By 25th july)






